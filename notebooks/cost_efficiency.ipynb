{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f34443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent working directory: /proj/sourasb-220503/IoT_attack_CL_IDS/results\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cw = os.getcwd()\n",
    "pwd = os.path.abspath(os.path.join(cw, \"..\", \"results\"))\n",
    "print(f\"Parent working directory: {pwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e216f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def training_cost(files):\n",
    "    all_eff_values = []  # collect efficiency_values per file\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            try:\n",
    "                domain_training_cost = data.get(\"domain_training_cost\", {})\n",
    "                efficiency_values = [v[0] for v in domain_training_cost.values() if v]\n",
    "               #  print(f\"{file}: {efficiency_values}\")\n",
    "                all_eff_values.append(efficiency_values)\n",
    "            except (KeyError, IndexError) as e:\n",
    "                print(f\"Problem with {file}: {e}\")\n",
    "\n",
    "    # --- Now compute element-wise average ---\n",
    "    if not all_eff_values:\n",
    "        print(\"No efficiency values found at all.\")\n",
    "        return None\n",
    "\n",
    "    # Ensure all lists have the same length\n",
    "    min_len = min(len(lst) for lst in all_eff_values)\n",
    "    trimmed = [lst[:min_len] for lst in all_eff_values]\n",
    "\n",
    "    # Convert to numpy array: shape = (num_files, min_len)\n",
    "    arr = np.array(trimmed, dtype=float)\n",
    "\n",
    "    # Element-wise mean across axis=0\n",
    "    avg_position_wise = np.mean(arr, axis=0)\n",
    "\n",
    "    print(\"\\n===== Results =====\")\n",
    "    # print(f\"Stacked values:\\n{arr}\")\n",
    "    # print(f\"Position-wise average:\\n{avg_position_wise.tolist()}\")\n",
    "\n",
    "    # print(f\"overall_mean: {np.mean(avg_position_wise)}\")\n",
    "    \n",
    "    return avg_position_wise.tolist(), np.mean(avg_position_wise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58cc53",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4738cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Results =====\n",
      "wcl_mean: 19.947065373848698\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 82.00920257943734\n",
      "\n",
      "===== Results =====\n",
      "si_mean: 26.310628627575678\n",
      "\n",
      "===== Results =====\n",
      "LwF_mean: 32.15812802513715\n",
      "E_geom_mean_WCL:1.00\n",
      "E_geom_mean_EWC:0.29\n",
      "E_geom_mean_SI:0.76\n",
      "E_geom_mean_LWF:0.62\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cost_replay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 88\u001b[0m\n\u001b[1;32m     84\u001b[0m E_geom_mean_lwf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(E) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(min_per_entry))\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE_geom_mean_LWF:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mE_geom_mean_lwf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m E \u001b[38;5;241m=\u001b[39m min_per_entry \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcost_replay\u001b[49m)\n\u001b[1;32m     89\u001b[0m E_geom_mean_replay \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(E) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(min_per_entry))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE_geom_mean_Replay:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mE_geom_mean_replay\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cost_replay' is not defined"
     ]
    }
   ],
   "source": [
    "# List of files\n",
    "\n",
    "files_1 = [ pwd + \"/1_experiment_results_LSTM_WCL_random.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_WCL_random.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_WCL_random.json\"\n",
    "]\n",
    "\n",
    "cost_wcl, avg_cost = training_cost(files_1)\n",
    "# print(f\"wcl_cost : {cost_wcl}\")\n",
    "print(f\"wcl_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_2 = [ pwd + \"/1_experiment_results_LSTM_EWC_random.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_EWC_random.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_EWC_random.json\"\n",
    "]\n",
    "\n",
    "cost_ewc, avg_cost = training_cost(files_2)\n",
    "# print(f\"ewc_cost : {cost_ewc}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_3 = [ pwd + \"/1_experiment_results_LSTM_SI_random.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_SI_random.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_SI_random.json\"\n",
    "]\n",
    "\n",
    "cost_si, avg_cost = training_cost(files_3)\n",
    "# print(f\"si_cost : {cost_si}\")\n",
    "print(f\"si_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_4 = [ pwd + \"/1_experiment_results_LSTM_LwF_random_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_LwF_random_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_LwF_random_alpha_1.0_T_4.0.json\"\n",
    "]\n",
    "\n",
    "cost_lwf, avg_cost = training_cost(files_4)\n",
    "# print(f\"LwF_cost : {cost_lwf}\")\n",
    "print(f\"LwF_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\"\"\"files_5 = [ pwd + \"/1_experiment_results_LSTM_Replay_REPLAY_random.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_Replay_REPLAY_random.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_Replay_REPLAY_random.json\"\n",
    "]\n",
    "\n",
    "cost_replay, avg_cost = training_cost(files_5)\n",
    "# print(f\"replay_cost : {cost_replay}\")\n",
    "print(f\"replay_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_6 = [ pwd + \"/1_experiment_results_LSTM_GR_random.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_GR_random.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_GR_random.json\"\n",
    "]\n",
    "\n",
    "cost_gr, avg_cost = training_cost(files_6)\n",
    "# print(f\"ewc_cost : {cost_gr}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\"\"\"\n",
    "\n",
    "arr = np.array([cost_wcl, cost_ewc, cost_si, cost_lwf], dtype=float) # , cost_replay, cost_gr], dtype=float)\n",
    "\n",
    "min_per_entry = np.min(arr, axis=0)\n",
    "\n",
    "# print(f\"min per entry : {min_per_entry}\")\n",
    "\n",
    "\n",
    "E = min_per_entry / np.array(cost_wcl)\n",
    "E_geom_mean_WCL = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_WCL:{E_geom_mean_WCL:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_ewc)\n",
    "E_geom_mean_ewc = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_EWC:{E_geom_mean_ewc:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_si)\n",
    "E_geom_mean_si = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_SI:{E_geom_mean_si:.2f}\")\n",
    "\n",
    "\n",
    "E = min_per_entry / np.array(cost_lwf)\n",
    "E_geom_mean_lwf = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_LWF:{E_geom_mean_lwf:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_replay)\n",
    "E_geom_mean_replay = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_Replay:{E_geom_mean_replay:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_gr)\n",
    "E_geom_mean_gr = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_GR:{E_geom_mean_gr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e35bd",
   "metadata": {},
   "source": [
    "# B2W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af238a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Results =====\n",
      "wcl_mean: 15.60321699824514\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 72.71676764208273\n",
      "\n",
      "===== Results =====\n",
      "si_mean: 18.76345672449679\n",
      "\n",
      "===== Results =====\n",
      "LwF_mean: 24.564780953128423\n",
      "\n",
      "===== Results =====\n",
      "replay_mean: 28.775021465366688\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 36.925078551559835\n",
      "E_geom_mean_WCL:0.96\n",
      "E_geom_mean_EWC:0.22\n",
      "E_geom_mean_SI:0.80\n",
      "E_geom_mean_LWF:0.61\n",
      "E_geom_mean_Replay:0.52\n",
      "E_geom_mean_GR:0.40\n"
     ]
    }
   ],
   "source": [
    "# List of files\n",
    "\n",
    "files_1 = [ pwd + \"/1_experiment_results_LSTM_WCL_b2w.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_WCL_b2w.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_WCL_b2w.json\"\n",
    "]\n",
    "\n",
    "cost_wcl, avg_cost = training_cost(files_1)\n",
    "# print(f\"wcl_cost : {cost_wcl}\")\n",
    "print(f\"wcl_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_2 = [ pwd + \"/1_experiment_results_LSTM_EWC_b2w.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_EWC_b2w.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_EWC_b2w.json\"\n",
    "]\n",
    "\n",
    "cost_ewc, avg_cost = training_cost(files_2)\n",
    "# print(f\"ewc_cost : {cost_ewc}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_3 = [ pwd + \"/1_experiment_results_LSTM_SI_b2w.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_SI_b2w.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_SI_b2w.json\"\n",
    "]\n",
    "\n",
    "cost_si, avg_cost = training_cost(files_3)\n",
    "# print(f\"si_cost : {cost_si}\")\n",
    "print(f\"si_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_4 = [ pwd + \"/1_experiment_results_LSTM_LwF_b2w_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_LwF_b2w_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_LwF_b2w_alpha_1.0_T_4.0.json\"\n",
    "]\n",
    "\n",
    "cost_lwf, avg_cost = training_cost(files)\n",
    "# print(f\"LwF_cost : {cost_lwf}\")\n",
    "print(f\"LwF_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_5 = [ pwd + \"/1_experiment_results_LSTM_Replay_REPLAY_b2w.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_Replay_REPLAY_b2w.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_Replay_REPLAY_b2w.json\"\n",
    "]\n",
    "\n",
    "cost_replay, avg_cost = training_cost(files_5)\n",
    "# print(f\"replay_cost : {cost_replay}\")\n",
    "print(f\"replay_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_6 = [ pwd + \"/1_experiment_results_LSTM_GR_b2w.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_GR_b2w.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_GR_b2w.json\"\n",
    "]\n",
    "\n",
    "cost_gr, avg_cost = training_cost(files_6)\n",
    "# print(f\"ewc_cost : {cost_gr}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "arr = np.array([cost_wcl, cost_ewc, cost_si, cost_lwf, cost_replay, cost_gr], dtype=float)\n",
    "\n",
    "min_per_entry = np.min(arr, axis=0)\n",
    "\n",
    "# print(f\"min per entry : {min_per_entry}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_wcl)\n",
    "E_geom_mean_WCL = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_WCL:{E_geom_mean_WCL:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_ewc)\n",
    "E_geom_mean_ewc = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_EWC:{E_geom_mean_ewc:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_si)\n",
    "E_geom_mean_si = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_SI:{E_geom_mean_si:.2f}\")\n",
    "\n",
    "\n",
    "E = min_per_entry / np.array(cost_lwf)\n",
    "E_geom_mean_lwf = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_LWF:{E_geom_mean_lwf:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_replay)\n",
    "E_geom_mean_replay = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_Replay:{E_geom_mean_replay:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_gr)\n",
    "E_geom_mean_gr = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_GR:{E_geom_mean_gr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ae608",
   "metadata": {},
   "source": [
    "# W2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39ec6d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Results =====\n",
      "wcl_mean: 21.66962158028198\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 106.41645352688568\n",
      "\n",
      "===== Results =====\n",
      "si_mean: 20.457159376128402\n",
      "\n",
      "===== Results =====\n",
      "LwF_mean: 24.564780953128423\n",
      "\n",
      "===== Results =====\n",
      "replay_mean: 28.088501473334166\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 36.00402948717399\n",
      "E_geom_mean_WCL:0.85\n",
      "E_geom_mean_EWC:0.20\n",
      "E_geom_mean_SI:0.92\n",
      "E_geom_mean_LWF:0.76\n",
      "E_geom_mean_Replay:0.66\n",
      "E_geom_mean_GR:0.51\n"
     ]
    }
   ],
   "source": [
    "# List of files\n",
    "\n",
    "files_1 = [ pwd + \"/1_experiment_results_LSTM_WCL_w2b.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_WCL_w2b.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_WCL_w2b.json\"\n",
    "]\n",
    "\n",
    "cost_wcl, avg_cost = training_cost(files_1)\n",
    "# print(f\"wcl_cost : {cost_wcl}\")\n",
    "print(f\"wcl_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_2 = [ pwd + \"/1_experiment_results_LSTM_EWC_w2b.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_EWC_w2b.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_EWC_w2b.json\"\n",
    "]\n",
    "\n",
    "cost_ewc, avg_cost = training_cost(files_2)\n",
    "# print(f\"ewc_cost : {cost_ewc}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_3 = [ pwd + \"/1_experiment_results_LSTM_SI_w2b.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_SI_w2b.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_SI_w2b.json\"\n",
    "]\n",
    "\n",
    "cost_si, avg_cost = training_cost(files_3)\n",
    "# print(f\"si_cost : {cost_si}\")\n",
    "print(f\"si_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_4 = [ pwd + \"/1_experiment_results_LSTM_LwF_w2b_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_LwF_w2b_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_LwF_w2b_alpha_1.0_T_4.0.json\"\n",
    "]\n",
    "\n",
    "cost_lwf, avg_cost = training_cost(files)\n",
    "# print(f\"LwF_cost : {cost_lwf}\")\n",
    "print(f\"LwF_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_5 = [ pwd + \"/1_experiment_results_LSTM_Replay_REPLAY_w2b.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_Replay_REPLAY_w2b.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_Replay_REPLAY_w2b.json\"\n",
    "]\n",
    "\n",
    "cost_replay, avg_cost = training_cost(files_5)\n",
    "# print(f\"replay_cost : {cost_replay}\")\n",
    "print(f\"replay_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_6 = [ pwd + \"/1_experiment_results_LSTM_GR_w2b.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_GR_w2b.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_GR_w2b.json\"\n",
    "]\n",
    "\n",
    "cost_gr, avg_cost = training_cost(files_6)\n",
    "# print(f\"ewc_cost : {cost_gr}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "arr = np.array([cost_wcl, cost_ewc, cost_si, cost_lwf, cost_replay, cost_gr], dtype=float)\n",
    "\n",
    "min_per_entry = np.min(arr, axis=0)\n",
    "\n",
    "# print(f\"min per entry : {min_per_entry}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_wcl)\n",
    "E_geom_mean_WCL = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_WCL:{E_geom_mean_WCL:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_ewc)\n",
    "E_geom_mean_ewc = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_EWC:{E_geom_mean_ewc:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_si)\n",
    "E_geom_mean_si = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_SI:{E_geom_mean_si:.2f}\")\n",
    "\n",
    "\n",
    "E = min_per_entry / np.array(cost_lwf)\n",
    "E_geom_mean_lwf = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_LWF:{E_geom_mean_lwf:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_replay)\n",
    "E_geom_mean_replay = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_Replay:{E_geom_mean_replay:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_gr)\n",
    "E_geom_mean_gr = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_GR:{E_geom_mean_gr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5a685",
   "metadata": {},
   "source": [
    "## Toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a8012b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Results =====\n",
      "wcl_mean: 16.44699816615159\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 104.84323615795195\n",
      "\n",
      "===== Results =====\n",
      "si_mean: 19.91435748939289\n",
      "\n",
      "===== Results =====\n",
      "LwF_mean: 24.564780953128423\n",
      "\n",
      "===== Results =====\n",
      "replay_mean: 27.478003215600946\n",
      "\n",
      "===== Results =====\n",
      "ewc_mean: 36.606197195651475\n",
      "E_geom_mean_WCL:0.96\n",
      "E_geom_mean_EWC:0.18\n",
      "E_geom_mean_SI:0.78\n",
      "E_geom_mean_LWF:0.64\n",
      "E_geom_mean_Replay:0.57\n",
      "E_geom_mean_GR:0.42\n"
     ]
    }
   ],
   "source": [
    "# List of files\n",
    "\n",
    "files_1 = [ pwd + \"/1_experiment_results_LSTM_WCL_toggle.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_WCL_toggle.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_WCL_toggle.json\"\n",
    "]\n",
    "\n",
    "cost_wcl, avg_cost = training_cost(files_1)\n",
    "# print(f\"wcl_cost : {cost_wcl}\")\n",
    "print(f\"wcl_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_2 = [ pwd + \"/1_experiment_results_LSTM_EWC_toggle.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_EWC_toggle.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_EWC_toggle.json\"\n",
    "\n",
    "]\n",
    "\n",
    "cost_ewc, avg_cost = training_cost(files_2)\n",
    "# print(f\"ewc_cost : {cost_ewc}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_3 = [ pwd + \"/1_experiment_results_LSTM_SI_toggle.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_SI_toggle.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_SI_toggle.json\"\n",
    "]\n",
    "\n",
    "cost_si, avg_cost = training_cost(files_3)\n",
    "# print(f\"si_cost : {cost_si}\")\n",
    "print(f\"si_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "\n",
    "files_4 = [ pwd + \"/1_experiment_results_LSTM_LwF_toggle_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_LwF_toggle_alpha_1.0_T_4.0.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_LwF_toggle_alpha_1.0_T_4.0.json\"\n",
    "]\n",
    "\n",
    "cost_lwf, avg_cost = training_cost(files)\n",
    "# print(f\"LwF_cost : {cost_lwf}\")\n",
    "print(f\"LwF_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_5 = [ pwd + \"/1_experiment_results_LSTM_Replay_REPLAY_toggle.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_Replay_REPLAY_toggle.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_Replay_REPLAY_toggle.json\"\n",
    "]\n",
    "\n",
    "cost_replay, avg_cost = training_cost(files_5)\n",
    "# print(f\"replay_cost : {cost_replay}\")\n",
    "print(f\"replay_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "files_6 = [ pwd + \"/1_experiment_results_LSTM_GR_toggle.json\",\n",
    "    pwd + \"/2_experiment_results_LSTM_GR_toggle.json\",\n",
    "    pwd + \"/3_experiment_results_LSTM_GR_toggle.json\"\n",
    "]\n",
    "\n",
    "cost_gr, avg_cost = training_cost(files_6)\n",
    "# print(f\"ewc_cost : {cost_gr}\")\n",
    "print(f\"ewc_mean: {np.mean( avg_cost)}\")\n",
    "\n",
    "arr = np.array([cost_wcl, cost_ewc, cost_si, cost_lwf, cost_replay, cost_gr], dtype=float)\n",
    "\n",
    "min_per_entry = np.min(arr, axis=0)\n",
    "\n",
    "# print(f\"min per entry : {min_per_entry}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_wcl)\n",
    "E_geom_mean_WCL = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_WCL:{E_geom_mean_WCL:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_ewc)\n",
    "E_geom_mean_ewc = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_EWC:{E_geom_mean_ewc:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_si)\n",
    "E_geom_mean_si = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_SI:{E_geom_mean_si:.2f}\")\n",
    "\n",
    "\n",
    "E = min_per_entry / np.array(cost_lwf)\n",
    "E_geom_mean_lwf = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_LWF:{E_geom_mean_lwf:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_replay)\n",
    "E_geom_mean_replay = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_Replay:{E_geom_mean_replay:.2f}\")\n",
    "\n",
    "E = min_per_entry / np.array(cost_gr)\n",
    "E_geom_mean_gr = np.prod(E) ** (1/len(min_per_entry))\n",
    "\n",
    "print(f\"E_geom_mean_GR:{E_geom_mean_gr:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
