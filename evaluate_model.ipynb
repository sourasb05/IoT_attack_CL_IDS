{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4c53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim, num_layers=1, fc_hidden_dim=64, head_dropout: float = 0.0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, fc_hidden_dim)\n",
    "        self.fc2 = nn.Linear(fc_hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        device = x.device\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "\n",
    "        out, (h_n, c_n) = self.lstm(x, (h0, c0))   # out: (B, T, H)\n",
    "\n",
    "        # Take last time step\n",
    "        feat = out[:, -1, :]                        # (B, H)\n",
    "\n",
    "        # Two-layer head\n",
    "        feat = F.relu(self.fc1(feat))\n",
    "        feat = self.dropout(feat)\n",
    "        logits = self.fc2(feat)                     # raw logits (B, C)\n",
    "\n",
    "        return logits, (h_n, c_n)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27967f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blackhole_var10_base', 'blackhole_var10_dec', 'blackhole_var10_oo', 'blackhole_var15_base', 'blackhole_var15_dec', 'blackhole_var15_oo', 'blackhole_var20_base', 'blackhole_var20_dec', 'blackhole_var20_oo', 'blackhole_var5_base', 'blackhole_var5_dec', 'blackhole_var5_oo', 'disflooding_var10_base', 'disflooding_var10_dec', 'disflooding_var10_oo', 'disflooding_var15_base', 'disflooding_var15_dec', 'disflooding_var15_oo', 'disflooding_var20_base', 'disflooding_var20_dec', 'disflooding_var20_oo', 'disflooding_var5_base', 'disflooding_var5_dec', 'disflooding_var5_oo', 'localrepair_var10_base', 'localrepair_var10_dec', 'localrepair_var10_oo', 'localrepair_var15_base', 'localrepair_var15_dec', 'localrepair_var15_oo', 'localrepair_var20_base', 'localrepair_var20_dec', 'localrepair_var20_oo', 'localrepair_var5_base', 'localrepair_var5_dec', 'localrepair_var5_oo', 'worstparent_var10_base', 'worstparent_var10_dec', 'worstparent_var10_oo', 'worstparent_var15_base', 'worstparent_var15_dec', 'worstparent_var15_oo', 'worstparent_var20_base', 'worstparent_var20_dec', 'worstparent_var20_oo', 'worstparent_var5_base', 'worstparent_var5_dec', 'worstparent_var5_oo'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils as utils\n",
    "import os\n",
    "\n",
    "evaluate_order = [\"blackhole_var5_base\", \"disflooding_var5_base\", \"worstparent_var5_base\", \"localrepair_var5_base\"]\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "domains_path = current_directory + '/data/attack_data'\n",
    "\n",
    "domains = utils.create_domains(domains_path)\n",
    "\n",
    "train_domains_loader = {}\n",
    "test_domains_loader = {}\n",
    "\n",
    "         \n",
    "domains = utils.create_domains(domains_path)\n",
    "\n",
    "train_domains_loader = {}\n",
    "test_domains_loader = {}\n",
    "\n",
    "for key, files in domains.items():\n",
    "    _, test_domains_loader[key] = utils.load_data(domains_path, key, files, window_size=10, step_size=3, batch_size=256)\n",
    "    \n",
    "print(test_domains_loader.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3899441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score,\n",
    "    roc_auc_score, roc_curve, auc, average_precision_score, confusion_matrix, balanced_accuracy_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, y_prob, test_domain_name, training_domain_name):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics including confusion matrix, specificity, and balanced accuracy,\n",
    "    plot the ROC curve, log and print the results, and return all metrics in a dictionary.\n",
    "    \n",
    "    Args:\n",
    "      y_true (np.array): True labels.\n",
    "      y_pred (np.array): Predicted labels.\n",
    "      y_prob (np.array): Predicted probabilities for the positive class.\n",
    "      test_domain_name (str): Name of the test domain.\n",
    "      training_domain_name (str): Name of the training domain.\n",
    "      \n",
    "    Returns:\n",
    "      metrics (dict): Dictionary with evaluation metrics.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    avg_precision = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    # Compute confusion matrix and additional metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # logging.info(f\"Confusion matrix shape: {cm.shape}, values: \\n{cm}\")\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    log_msg = (f\"Train Domain: {training_domain_name} | Test Domain: {test_domain_name} | \"\n",
    "               f\"Acc: {accuracy:.4f} | Prec: {precision:.4f} | Rec: {recall:.4f} | \"\n",
    "               f\"F1: {f1:.4f} | \"\n",
    "               f\"Specificity: {specificity:.4f} | Balanced Acc: {balanced_acc:.4f} | \"\n",
    "               f\"CM: {cm.tolist()}\")    # ROC-AUC: {roc_auc:.4f} \n",
    "    # print(log_msg)\n",
    "    # logging.info(log_msg)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": avg_precision,\n",
    "        \"specificity\": specificity,\n",
    "        \"balanced_accuracy\": balanced_acc,\n",
    "        \"confusion_matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6402ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "import evaluation as evaluate\n",
    "from utils import confidence_from_logits\n",
    "\n",
    "\n",
    "def eval_model(model,test_domain_loader, train_domain, device, domain_id=None):\n",
    "    all_y_true, all_y_pred, all_y_prob = [], [], []\n",
    "    all_confidences, all_conf_correct, all_conf_incorrect = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_domain_loader[train_domain]:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            if domain_id is not None:\n",
    "                outputs, _ = model(X_batch, domain_id=domain_id)  # Pass domain_id to the model\n",
    "            else:\n",
    "                outputs, _ = model(X_batch)  # Pass domain_id to the model\n",
    "            \n",
    "            # === confidence here (eval only) ===\n",
    "            probs, preds, confs = confidence_from_logits(outputs)\n",
    "            all_y_true.extend(y_batch.cpu().numpy())\n",
    "            all_y_pred.extend(preds.cpu().numpy())\n",
    "            all_y_prob.extend(probs[:, 1].cpu().numpy())   # you already use class-1 prob for ROC\n",
    "            all_confidences.extend(confs.cpu().numpy())\n",
    "\n",
    "            correct_mask = (preds == y_batch)\n",
    "            if correct_mask.any():\n",
    "                all_conf_correct.extend(confs[correct_mask].cpu().numpy())\n",
    "            if (~correct_mask).any():\n",
    "                all_conf_incorrect.extend(confs[~correct_mask].cpu().numpy())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_y_true.extend(y_batch.cpu().numpy())\n",
    "            all_y_pred.extend(predicted.cpu().numpy())\n",
    "            all_y_prob.extend(torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy())\n",
    "        \n",
    "    metrics = evaluate.evaluate_metrics(np.array(all_y_true), np.array(all_y_pred),\n",
    "                        np.array(all_y_prob), train_domain, train_domain)\n",
    "    \n",
    "    avg_conf           = float(np.mean(all_confidences))   if all_confidences else float(\"nan\")\n",
    "    avg_conf_correct   = float(np.mean(all_conf_correct))  if all_conf_correct else float(\"nan\")\n",
    "    avg_conf_incorrect = float(np.mean(all_conf_incorrect))if all_conf_incorrect else float(\"nan\")\n",
    "    metrics[\"avg_conf\"] = avg_conf\n",
    "    metrics[\"avg_conf_correct\"] = avg_conf_correct\n",
    "    metrics[\"avg_conf_incorrect\"] = avg_conf_incorrect\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030db7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating scenario: blackhole_var5_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training on blackhole_var5_base and testing on blackhole_var5_base: {'accuracy': 0.837037037037037, 'precision': 0.8517064234045367, 'recall': 0.837037037037037, 'f1': 0.8357618331286198, 'roc_auc': 0.8117537467061924, 'average_precision': 0.8856491704770661, 'specificity': 0.9356060606060606, 'balanced_accuracy': 0.8391798418972332, 'confusion_matrix': array([[1976,  136],\n",
      "       [ 568, 1640]]), 'avg_conf': 0.8798449635505676, 'avg_conf_correct': 0.8805820941925049, 'avg_conf_incorrect': 0.8760589361190796}\n",
      "Metrics for training on blackhole_var5_base and testing on disflooding_var5_base: {'accuracy': 0.5005841121495327, 'precision': 0.5006905730029898, 'recall': 0.5005841121495327, 'f1': 0.5006084795275568, 'roc_auc': 0.3037864186341101, 'average_precision': 0.40984617005376145, 'specificity': 0.5011848341232228, 'balanced_accuracy': 0.5005924170616114, 'confusion_matrix': array([[1692, 1684],\n",
      "       [1736, 1736]]), 'avg_conf': 0.9929722547531128, 'avg_conf_correct': 0.9866450428962708, 'avg_conf_incorrect': 0.9993142485618591}\n",
      "Metrics for training on blackhole_var5_base and testing on worstparent_var5_base: {'accuracy': 0.6185393258426967, 'precision': 0.7848924393640897, 'recall': 0.6185393258426967, 'f1': 0.5566081453624447, 'roc_auc': 0.48722971983292007, 'average_precision': 0.6258010344158407, 'specificity': 1.0, 'balanced_accuracy': 0.6236141906873615, 'confusion_matrix': array([[3512,    0],\n",
      "       [2716,  892]]), 'avg_conf': 0.989681601524353, 'avg_conf_correct': 0.9893604516983032, 'avg_conf_incorrect': 0.9902021884918213}\n",
      "Metrics for training on blackhole_var5_base and testing on localrepair_var5_base: {'accuracy': 0.5202247191011236, 'precision': 0.7567882813919091, 'recall': 0.5202247191011236, 'f1': 0.3830703272452085, 'roc_auc': 0.39898144593891577, 'average_precision': 0.564808243135718, 'specificity': 1.0, 'balanced_accuracy': 0.5266075388026608, 'confusion_matrix': array([[3512,    0],\n",
      "       [3416,  192]]), 'avg_conf': 0.9767604470252991, 'avg_conf_correct': 0.9840810298919678, 'avg_conf_incorrect': 0.9688226580619812}\n",
      "Evaluating scenario: disflooding_var5_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training on disflooding_var5_base and testing on blackhole_var5_base: {'accuracy': 0.5550925925925926, 'precision': 0.5578818118902508, 'recall': 0.5550925925925926, 'f1': 0.5417206680364576, 'roc_auc': 0.5992062266688626, 'average_precision': 0.5942305460311652, 'specificity': 0.3816287878787879, 'balanced_accuracy': 0.5513216403162056, 'confusion_matrix': array([[ 806, 1306],\n",
      "       [ 616, 1592]]), 'avg_conf': 0.97314453125, 'avg_conf_correct': 0.9790336489677429, 'avg_conf_incorrect': 0.9657968282699585}\n",
      "Metrics for training on disflooding_var5_base and testing on disflooding_var5_base: {'accuracy': 0.9985397196261683, 'precision': 0.9985440323266226, 'recall': 0.9985397196261683, 'f1': 0.9985397464101843, 'roc_auc': 0.9999331142027212, 'average_precision': 0.9999374703870548, 'specificity': 1.0, 'balanced_accuracy': 0.9985599078341014, 'confusion_matrix': array([[3376,    0],\n",
      "       [  10, 3462]]), 'avg_conf': 0.9954902529716492, 'avg_conf_correct': 0.9957225918769836, 'avg_conf_incorrect': 0.8366597294807434}\n",
      "Metrics for training on disflooding_var5_base and testing on worstparent_var5_base: {'accuracy': 0.49634831460674156, 'precision': 0.7507995605661985, 'recall': 0.49634831460674156, 'f1': 0.3326877689410385, 'roc_auc': 0.5670008813620959, 'average_precision': 0.6916583312590925, 'specificity': 1.0, 'balanced_accuracy': 0.5030487804878049, 'confusion_matrix': array([[3512,    0],\n",
      "       [3586,   22]]), 'avg_conf': 0.9992421865463257, 'avg_conf_correct': 0.9995339512825012, 'avg_conf_incorrect': 0.9989545345306396}\n",
      "Metrics for training on disflooding_var5_base and testing on localrepair_var5_base: {'accuracy': 0.5845505617977528, 'precision': 0.7744886511644062, 'recall': 0.5845505617977528, 'f1': 0.5018015621155906, 'roc_auc': 0.20896457631484575, 'average_precision': 0.49163227388326924, 'specificity': 1.0, 'balanced_accuracy': 0.5900776053215078, 'confusion_matrix': array([[3512,    0],\n",
      "       [2958,  650]]), 'avg_conf': 0.9992325305938721, 'avg_conf_correct': 0.9990513324737549, 'avg_conf_incorrect': 0.9994874596595764}\n",
      "Evaluating scenario: worstparent_var5_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training on worstparent_var5_base and testing on blackhole_var5_base: {'accuracy': 0.5111111111111111, 'precision': 0.26123456790123456, 'recall': 0.5111111111111111, 'f1': 0.3457516339869281, 'roc_auc': 0.5, 'average_precision': 0.5111111111111111, 'specificity': 0.0, 'balanced_accuracy': 0.5, 'confusion_matrix': array([[   0, 2112],\n",
      "       [   0, 2208]]), 'avg_conf': 1.0, 'avg_conf_correct': 1.0, 'avg_conf_incorrect': 1.0}\n",
      "Metrics for training on worstparent_var5_base and testing on disflooding_var5_base: {'accuracy': 0.5070093457943925, 'precision': 0.25705847672285786, 'recall': 0.5070093457943925, 'f1': 0.3411504745345215, 'roc_auc': 0.5, 'average_precision': 0.5070093457943925, 'specificity': 0.0, 'balanced_accuracy': 0.5, 'confusion_matrix': array([[   0, 3376],\n",
      "       [   0, 3472]]), 'avg_conf': 1.0, 'avg_conf_correct': 1.0, 'avg_conf_incorrect': 1.0}\n",
      "Metrics for training on worstparent_var5_base and testing on worstparent_var5_base: {'accuracy': 0.7452247191011236, 'precision': 0.8242282930575298, 'recall': 0.7452247191011236, 'f1': 0.7298480033730231, 'roc_auc': 0.696069131365884, 'average_precision': 0.7982658460338388, 'specificity': 0.9908883826879271, 'balanced_accuracy': 0.7484929718317684, 'confusion_matrix': array([[3480,   32],\n",
      "       [1782, 1826]]), 'avg_conf': 0.8586663007736206, 'avg_conf_correct': 0.8584433197975159, 'avg_conf_incorrect': 0.8593184947967529}\n",
      "Metrics for training on worstparent_var5_base and testing on localrepair_var5_base: {'accuracy': 0.5067415730337078, 'precision': 0.25678702184067664, 'recall': 0.5067415730337078, 'f1': 0.34085078215988396, 'roc_auc': 0.5250706794316856, 'average_precision': 0.5195925273205424, 'specificity': 0.0, 'balanced_accuracy': 0.5, 'confusion_matrix': array([[   0, 3512],\n",
      "       [   0, 3608]]), 'avg_conf': 1.0, 'avg_conf_correct': 1.0, 'avg_conf_incorrect': 1.0}\n",
      "Evaluating scenario: localrepair_var5_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/x_souba/anaconda3/envs/personalized_fl/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training on localrepair_var5_base and testing on blackhole_var5_base: {'accuracy': 0.5111111111111111, 'precision': 0.26123456790123456, 'recall': 0.5111111111111111, 'f1': 0.3457516339869281, 'roc_auc': 0.5, 'average_precision': 0.5111111111111111, 'specificity': 0.0, 'balanced_accuracy': 0.5, 'confusion_matrix': array([[   0, 2112],\n",
      "       [   0, 2208]]), 'avg_conf': 1.0, 'avg_conf_correct': 1.0, 'avg_conf_incorrect': 1.0}\n",
      "Metrics for training on localrepair_var5_base and testing on disflooding_var5_base: {'accuracy': 0.5467289719626168, 'precision': 0.7606817199899948, 'recall': 0.5467289719626168, 'f1': 0.4239015897980561, 'roc_auc': 0.7448750464105531, 'average_precision': 0.6686503916895805, 'specificity': 0.08056872037914692, 'balanced_accuracy': 0.5402843601895735, 'confusion_matrix': array([[ 272, 3104],\n",
      "       [   0, 3472]]), 'avg_conf': 0.9900760650634766, 'avg_conf_correct': 0.9909858107566833, 'avg_conf_incorrect': 0.9889787435531616}\n",
      "Metrics for training on localrepair_var5_base and testing on worstparent_var5_base: {'accuracy': 0.4960674157303371, 'precision': 0.750730811837316, 'recall': 0.4960674157303371, 'f1': 0.3320709115865927, 'roc_auc': 0.49445392168251767, 'average_precision': 0.5515049969745937, 'specificity': 1.0, 'balanced_accuracy': 0.5027716186252772, 'confusion_matrix': array([[3512,    0],\n",
      "       [3588,   20]]), 'avg_conf': 0.9920162558555603, 'avg_conf_correct': 0.9921191334724426, 'avg_conf_incorrect': 0.9919149279594421}\n",
      "Metrics for training on localrepair_var5_base and testing on localrepair_var5_base: {'accuracy': 0.9974719101123596, 'precision': 0.9974848012222681, 'recall': 0.9974719101123596, 'f1': 0.99747198013714, 'roc_auc': 0.9997291516195344, 'average_precision': 0.9997605782391012, 'specificity': 1.0, 'balanced_accuracy': 0.9975055432372506, 'confusion_matrix': array([[3512,    0],\n",
      "       [  18, 3590]]), 'avg_conf': 0.9936465620994568, 'avg_conf_correct': 0.9938769340515137, 'avg_conf_incorrect': 0.9027745723724365}\n"
     ]
    }
   ],
   "source": [
    "for scenario in evaluate_order:\n",
    "    print(f\"Evaluating scenario: {scenario}\")\n",
    "    domains = utils.create_domains(domains_path)\n",
    "\n",
    "    # Add your evaluation code here\n",
    "    model = LSTMClassifier(input_dim=140, hidden_dim=10, output_dim=2, num_layers=1, fc_hidden_dim=10, head_dropout=0.05)\n",
    "    state_dict = torch.load(\n",
    "    current_directory + f\"/models/exp_no_1_LSTM_WCL_random/best_model_after_{scenario}.pt\",\n",
    "    map_location=torch.device(\"cpu\"), weights_only=True\n",
    "    )\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    for eval_scenario in evaluate_order:\n",
    "        metrics = eval_model(model=model,test_domain_loader=test_domains_loader, train_domain=eval_scenario, device=\"cpu\", domain_id=None)\n",
    "        print(f\"Metrics for training on {scenario} and testing on {eval_scenario}: {metrics}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
